\contentsline {figure}{\numberline {1}{\ignorespaces To find the best movie, the shown movies need to be filtered by the ones you like and the showtimes need to be filtered by the times you are available. All remaining showtimes need to be cross-references with the preferences of your friends. This is a lot of work and can be automated on the Semantic Web.\relax }}{2}
\contentsline {figure}{\numberline {2}{\ignorespaces The Universal Schema. Every row and every column is represented by an embedding (in purple). Green cells mean a row and column are in the context of the other. For example, the pair Bill and Microsoft are connected to \emph {chairman}. The embeddings are then trained so that the context can be predicted. That means the embeddings of Bill \& Microsoft and \emph {chairman} will become more similar.\relax }}{3}
\contentsline {figure}{\numberline {3}{\ignorespaces After the embeddings are learned, rows and columns with similar embeddings are connected (in light green). For example, the embeddings of Melinda \& Seattle and \emph {lives in} may have become very similar. In that case, the system connects the pair with that relation.\relax }}{4}
\contentsline {figure}{\numberline {4}{\ignorespaces The embedding of a row (in pink) is optimized to be close to its context embeddings (in purple) but far away from other embeddings (in red).\relax }}{5}
\contentsline {figure}{\numberline {5}{\ignorespaces Similar to how the embeddings are used to predict relations within an ontology, ontology matching can be done by predicting relations between two ontologies. For example, since Gates and Bill will have very similar sets of embeddings (as their contexts are very similar) the system will recognise they are the same entity.\relax }}{6}
\contentsline {figure}{\numberline {6}{\ignorespaces The different body parts of the mouse are connected as in this image.\relax }}{14}
\contentsline {figure}{\numberline {7}{\ignorespaces The different body parts of the man are connected as in this image.\relax }}{15}
\contentsline {figure}{\numberline {8}{\ignorespaces Humans and mice are connected as shown in this image.\relax }}{15}
\contentsline {figure}{\numberline {9}{\ignorespaces The precision and recall trade-off for the results of the untrained Node2vec. $AP = 0.04194$\relax }}{29}
\contentsline {figure}{\numberline {10}{\ignorespaces The precision and recall trade-off for the results of the Word2vec algorithm. $AP: 0.04636$\relax }}{30}
\contentsline {figure}{\numberline {11}{\ignorespaces The precision and recall trade-off for the results of the bidirectional Node2vec. $AP = 0.04198$\relax }}{30}
\contentsline {figure}{\numberline {12}{\ignorespaces The precision and recall trade-off for the results of the alternative DeepWalk algorithm. $AP = 0.04193$\relax }}{31}
