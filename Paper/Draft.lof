\contentsline {figure}{\numberline {1}{\ignorespaces To find the best movie, the shown movies need to be filtered by the ones you like and the showtimes need to be filtered by the times you are available. All remaining showtimes need to be cross-references with the preferences of your friends.\relax }}{1}
\contentsline {figure}{\numberline {2}{\ignorespaces The Universal Schema. Every row and every column is represented by an embedding (in purple). Green cells mean a row and column are in the context of the other. For example, the pair Bill and Microsoft are connected to \emph {chairman}. The embeddings are then trained so that the context can be predicted. That means the embeddings of Bill \& Microsoft and \emph {chairman} will become more similar.\relax }}{3}
\contentsline {figure}{\numberline {3}{\ignorespaces After the embeddings are learned, rows and columns with similar embeddings are connected (in light green). For example, the embeddings of Melinda \& Seattle and \emph {lives in} may have become very similar. In that case, the system connects the pair with that relation.\relax }}{4}
\contentsline {figure}{\numberline {4}{\ignorespaces The embedding of a row (in pink) is optimized to be close to its context embeddings (in purple) but far away from other embeddings (in red).\relax }}{5}
\contentsline {figure}{\numberline {5}{\ignorespaces Similar to how the embeddings are used to predict relations within an ontology, ontology matching can be done by predicting relations between two ontologies. For example, since Gates and Bill will have very similar sets of embeddings (as their contexts are very similar) the system will recognise they are the same entity.\relax }}{6}
\contentsline {figure}{\numberline {6}{\ignorespaces The first iteration of the Web consisted of static content, written by authors and read by readers.\relax }}{11}
\contentsline {figure}{\numberline {7}{\ignorespaces In the second iteration of the Web, readers have become users that can alter and add to the content found on the interactive hubs. This also allows users to interact with each other.\relax }}{12}
\contentsline {figure}{\numberline {8}{\ignorespaces On the third iteration of the Web, virtual agents are also able to read and write content and interact with humans (through question answering as an example). Virtual agents may also work together.\relax }}{12}
\contentsline {figure}{\numberline {9}{\ignorespaces An example of the Semantic Web represented as a graph of entities (in black) and relationships (in red). It contains many different kinds of entities, including countries and people.\relax }}{14}
\contentsline {figure}{\numberline {10}{\ignorespaces New information to be added to the Semantic Web.\relax }}{15}
\contentsline {figure}{\numberline {11}{\ignorespaces The new information is connected to the rest of the Semantic Web by connecting the new entities with entities in the Semantic Web.\relax }}{16}
\contentsline {figure}{\numberline {12}{\ignorespaces The different sub-graphs in the Semantic Web graph. They are contained in different Knowledge Bases and connected by URIs.\relax }}{17}
\contentsline {figure}{\numberline {13}{\ignorespaces \relax }}{18}
\contentsline {figure}{\numberline {14}{\ignorespaces \relax }}{18}
\contentsline {figure}{\numberline {15}{\ignorespaces The different body parts of the mouse are connected as in this image.\relax }}{20}
\contentsline {figure}{\numberline {16}{\ignorespaces The different body parts of the man are connected as in this image.\relax }}{21}
\contentsline {figure}{\numberline {17}{\ignorespaces Humans and mice are connected as shown in this image.\relax }}{21}
\contentsline {figure}{\numberline {18}{\ignorespaces The precision and recall trade-off for the results of the untrained Node2vec. $AP = 0.04194$\relax }}{37}
\contentsline {figure}{\numberline {19}{\ignorespaces The precision and recall trade-off for the results of the Word2vec algorithm. $AP: 0.04636$\relax }}{38}
\contentsline {figure}{\numberline {20}{\ignorespaces The precision and recall trade-off for the results of the bidirectional Node2vec. $AP = 0.04198$\relax }}{38}
\contentsline {figure}{\numberline {21}{\ignorespaces The precision and recall trade-off for the results of the alternative DeepWalk algorithm. $AP = 0.04193$\relax }}{39}
